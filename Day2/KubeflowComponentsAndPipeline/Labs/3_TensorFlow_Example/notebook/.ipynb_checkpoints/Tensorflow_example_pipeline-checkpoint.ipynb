{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install --user --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### component that obtains data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_data_op():\n",
    "    return dsl.ContainerOp(\n",
    "        name = 'Obtain Data',\n",
    "        image = ,\n",
    "        arguments = [],\n",
    "        file_outputs={\n",
    "            'data': '/obtain_data/data'\n",
    "        }      \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### component that does preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_op(data):\n",
    "    return dsl.ContainerOp(\n",
    "        name = 'Preprocess Data',\n",
    "        image = \n",
    "        arguments = [\n",
    "            '--data', data\n",
    "        ],\n",
    "        file_outputs={\n",
    "            'clean_data':'/preprocess_data/clean_data'      \n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### component for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_op(X_train, y_train):\n",
    "    return dsl.ContainerOp(\n",
    "        name = 'Train Model',\n",
    "        image = ,\n",
    "        arguments = [\n",
    "            '--clean_data', clean_data    \n",
    "        ],\n",
    "        file_outputs={\n",
    "            'X_test':'/train_data/X_test.npy',\n",
    "            'y_test':'/train_data/y_test.npy'  \n",
    "            'model':'/train_data/classifier.h5'\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### components for predicting on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_op(X_test, y_test, model):\n",
    "    return dsl.ContainerOp(\n",
    "        name='Predict Model',\n",
    "        image=\n",
    "        arguments = [\n",
    "            '--X_test', X_test,\n",
    "            '--y_test', y_test,\n",
    "            '--model', model\n",
    "        ],\n",
    "        file_outputs={\n",
    "            'results':'/predict_data/results'\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining pipeline and including its components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='Churn modelling pipeline',\n",
    "   description='An ML reusable pipeline that performs customer segmentation to determine customers with high risk of leaving a bank .'\n",
    ")\n",
    "\n",
    "# Define parameters to be fed into pipeline\n",
    "def churn_reuseable_pipeline():\n",
    "    _obtain_data_op = obtain_data_op()\n",
    "    \n",
    "    _preprocess_op = preprocess_op(\n",
    "        dsl.InputArgumentPath(_obtain_data_op.outputs['data'])).after(_obtain_data_op)\n",
    "    \n",
    "    _train_op = train_op(\n",
    "        dsl.InputArgumentPath(_preprocess_op.outputs['clean_data'])).after(_preprocess_op)\n",
    "\n",
    "    _predict_op = predict_op(\n",
    "        dsl.InputArgumentPath(_train_op.outputs['X_test']),\n",
    "        dsl.InputArgumentPath(_train_op.outputs['y_test']),\n",
    "        dsl.InputArgumentPath(_train_op.outputs['model'])).after(_train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile pipeline to generate compressed YAML definition of the pipeline.\n",
    "experiment_name = 'churn_analysis_pipeline'\n",
    "kfp.compiler.Compiler().compile(churn_reuseable_pipeline,  \n",
    "  '{}.zip'.format(experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client()\n",
    "client.create_run_from_pipeline_func(churn_reuseable_pipeline, arguments={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
