{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Customer Churn Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Installing and Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "!python -m pip install --user --upgrade pip\n",
    "\n",
    "!pip3 install pandas==0.23.4 matplotlib==3.0.3 seaborn==0.9.0 scikit-learn==0.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:load_data"
    ]
   },
   "outputs": [],
   "source": [
    "#importing the data\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/MavenCode/KubeflowTraining/master/Data/Telco/Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "#viewing the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "#size of data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "#frequency of the target classes\n",
    "sns.countplot(x='Exited', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "From the data we have more information on the customers that stayed at the bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "#checking for datatype of each column\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "#checking for missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:preprocess",
     "prev:load_data"
    ]
   },
   "outputs": [],
   "source": [
    "#dropping some columns that are not needed\n",
    "data = data.drop(columns=['RowNumber','CustomerId','Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "#viewing the unique values in Geography column\n",
    "data['Geography'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data features\n",
    "X = data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#target data\n",
    "y = data.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#encoding the categorical columns\n",
    "le = LabelEncoder()\n",
    "ohe = OneHotEncoder()\n",
    "X['Gender'] = le.fit_transform(X['Gender'])\n",
    "geo_df = pd.DataFrame(ohe.fit_transform(X[['Geography']]).toarray())\n",
    "\n",
    "#getting feature name after onehotencoding\n",
    "geo_df.columns = ohe.get_feature_names(['Geography'])\n",
    "\n",
    "#merging geo_df with the main data\n",
    "X = X.join(geo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dropping the old columns after encoding\n",
    "X.drop(columns=['Geography'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "#using heatmap see the correlation between each features\n",
    "plt.figure(figsize=(12,10))\n",
    "cor = data.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data=data, y_vars=['EstimatedSalary'], x_vars=['CreditScore', 'Gender','Age','Tenure','Balance','NumOfProducts','HasCrCard','IsActiveMember'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split( X,y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "data_dict = {\"X_train\":X_train, \"X_test\":X_test, \"y_train\":y_train, \"y_test\":y_test}\n",
    "for i in data_dict:\n",
    "    print(\"The shape of {} is {}\".format(i,data_dict[i].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc =StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#saving the values from the dataframe\n",
    "y_train = y_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Building the Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:modeling",
     "prev:preprocess"
    ]
   },
   "outputs": [],
   "source": [
    "#initializing the classifier model with its input, hidden and output layers\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 16, activation='relu', input_dim=12,))\n",
    "classifier.add(Dense(units = 8, activation='relu'))\n",
    "classifier.add(Dense(units = 1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Compiling the classifier model with Stochastic Gradient Desecnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss='binary_crossentropy' , metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Fitting the classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train, batch_size=10 , epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can see that the accuracy and loss of the model on the train dataset is 86% and 0.3146 respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Getting the model's predictions o  the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:",
     "prev:modeling"
    ]
   },
   "outputs": [],
   "source": [
    "# These probabilities would help determine which of the customers have high risk of leaving the bank\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "From the probabilities obtained above, the bank can segment each of the customers and know the ones to prevent from leaving\n",
    "by developing ideas to keep them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a threshold for the confution matrics\n",
    "y_pred=(y_pred>0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countFalse =0\n",
    "countTrue =0\n",
    "for i in y_pred:\n",
    "    if i[0] == False:\n",
    "        countFalse += 1\n",
    "    else:\n",
    "        countTrue += 1\n",
    "print(\"countF :{} and countT: {}\".format(countFalse,countTrue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:results",
     "prev:modeling"
    ]
   },
   "outputs": [],
   "source": [
    "# confusion metrics\n",
    "cm = confusion_matrix(y_test.values,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "From our confusion matrix we conclude that:\n",
    "1. **True positive:** 178(We predicted a positive result and it was positive)- the model rightly predicted the ones who left the bank \n",
    "2. **True negative:** 1545(We predicted a negative result and it was negative)-the model rightly predicted the ones who stayed at the bank \n",
    "3. **False positive:** 62(We predicted a positive result and it was negative)-the model predicted that these ones left when they actually stayed\n",
    "4. **False negative:** 215(We predicted a negative result and it was positive)- the model predicted that these ones stayed when they actually left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#classification report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(cr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "docker_image": "docker.io/mavencodev/kale:latest",
   "experiment": {
    "id": "new",
    "name": "churn analysis"
   },
   "experiment_name": "churn analysis",
   "pipeline_description": "An ML pipeline for churn using Kale",
   "pipeline_name": "churn-kale-pipeline",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
